{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a differentially private LSTM model for name classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial we will build a differentially-private LSTM model to classify names to their source languages, which is the same task as in the tutorial **NLP From Scratch** (https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html). Since the objective of this tutorial is to demonstrate the effective use of an LSTM with privacy guarantees, we will be utilizing it in place of the bare-bones RNN model defined in the original tutorial. Specifically, we use the `DPLSTM` module from `opacus.layers.dp_lstm` to facilitate calculation of the per-example gradients, which are utilized in the addition of noise during application of differential privacy. `DPLSTM` has the same API and functionality as the `nn.LSTM`, with some restrictions (ex. we currently support single layers, the full list is given below).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let us download the dataset of names and their associated language labels as given in https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html. We train our differentially-private LSTM on the same dataset as in that tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and extracting ...\n",
            "Completed!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "NAMES_DATASET_URL = \"https://download.pytorch.org/tutorial/data.zip\"\n",
        "DATA_DIR = \"names\"\n",
        "\n",
        "import zipfile\n",
        "import urllib\n",
        "\n",
        "def download_and_extract(dataset_url, data_dir):\n",
        "    print(\"Downloading and extracting ...\")\n",
        "    filename = \"data.zip\"\n",
        "\n",
        "    urllib.request.urlretrieve(dataset_url, filename)\n",
        "    with zipfile.ZipFile(filename) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(filename)\n",
        "    print(\"Completed!\")\n",
        "\n",
        "download_and_extract(NAMES_DATASET_URL, DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Arabic.txt', 'Chinese.txt', 'Czech.txt', 'Dutch.txt', 'English.txt', 'French.txt', 'German.txt', 'Greek.txt', 'Irish.txt', 'Italian.txt', 'Japanese.txt', 'Korean.txt', 'Polish.txt', 'Portuguese.txt', 'Russian.txt', 'Scottish.txt', 'Spanish.txt', 'Vietnamese.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "names_folder = os.path.join(DATA_DIR, 'data', 'names')\n",
        "all_filenames = []\n",
        "\n",
        "for language_file in os.listdir(names_folder):\n",
        "    all_filenames.append(os.path.join(names_folder, language_file))\n",
        "    \n",
        "print(os.listdir(names_folder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the functions `unicode_to_ascii()` and `build_category_lines()` in the cell below. `unicode_to_ascii()` reads in a string and normalizes all characters in it to ASCII, removing all other Unicode characters. `read_lines()` reads the names dataset from disk and then stores it in the variable `category_lines` which is a dict with key as language and value as list of names belonging to that language. `all_categories` is a list of supported languages, and `n_categories` is the number of languages. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string \n",
        "import unicodedata\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'#\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicode_to_ascii(s, all_letters):\n",
        "    return \"\".join(\n",
        "        c\n",
        "        for c in unicodedata.normalize(\"NFD\", s)\n",
        "        if unicodedata.category(c) != \"Mn\" and c in all_letters\n",
        "    )\n",
        "\n",
        "def read_lines(filename, all_letters):\n",
        "    with open(filename) as f_read:\n",
        "        lines = f_read.read().strip().split(\"\\n\")\n",
        "    return [unicode_to_ascii(line, all_letters) for line in lines]\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "for filename in all_filenames:\n",
        "    category = filename.split(\"/\")[-1].split(\".\")[0]\n",
        "    all_categories.append(category)\n",
        "    lines = read_lines(filename, all_letters)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We inspect the dictionary `all_categories` and for each language key, see a few representatives names in each. For each language, we also find the number of names in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language : Arabic , names = ['Khoury', 'Nahas', 'Daher', 'Gerges', 'Nazari'], # of names = 2000\n",
            "Language : Chinese , names = ['Ang', 'AuYong', 'Bai', 'Ban', 'Bao'], # of names = 268\n",
            "Language : Czech , names = ['Abl', 'Adsit', 'Ajdrna', 'Alt', 'Antonowitsch'], # of names = 519\n",
            "Language : Dutch , names = ['Aalsburg', 'Aalst', 'Aarle', 'Achteren', 'Achthoven'], # of names = 297\n",
            "Language : English , names = ['Abbas', 'Abbey', 'Abbott', 'Abdi', 'Abel'], # of names = 3668\n",
            "Language : French , names = ['Abel', 'Abraham', 'Adam', 'Albert', 'Allard'], # of names = 277\n",
            "Language : German , names = ['Abbing', 'Abel', 'Abeln', 'Abt', 'Achilles'], # of names = 724\n",
            "Language : Greek , names = ['Adamidis', 'Adamou', 'Agelakos', 'Akrivopoulos', 'Alexandropoulos'], # of names = 203\n",
            "Language : Irish , names = ['Adam', 'Ahearn', 'Aodh', 'Aodha', 'Aonghuis'], # of names = 232\n",
            "Language : Italian , names = ['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni'], # of names = 709\n",
            "Language : Japanese , names = ['Abe', 'Abukara', 'Adachi', 'Aida', 'Aihara'], # of names = 991\n",
            "Language : Korean , names = ['Ahn', 'Baik', 'Bang', 'Byon', 'Cha'], # of names = 94\n",
            "Language : Polish , names = ['Adamczak', 'Adamczyk', 'Andrysiak', 'Auttenberg', 'Bartosz'], # of names = 139\n",
            "Language : Portuguese , names = ['Abreu', 'Albuquerque', 'Almeida', 'Alves', 'Araujo'], # of names = 74\n",
            "Language : Russian , names = ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin'], # of names = 9408\n",
            "Language : Scottish , names = ['Smith', 'Brown', 'Wilson', 'Campbell', 'Stewart'], # of names = 100\n",
            "Language : Spanish , names = ['Abana', 'Abano', 'Abarca', 'Abaroa', 'Abascal'], # of names = 298\n",
            "Language : Vietnamese , names = ['Nguyen', 'Tron', 'Le', 'Pham', 'Huynh'], # of names = 73\n"
          ]
        }
      ],
      "source": [
        "for language, names in category_lines.items():\n",
        "    print(f\"Language : {language} , names = {names[:5]}, # of names = {len(names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training / Validation Set Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We split the dataset into a 80-20 split for training and validation. We stratify across languages and for each language, we randomly choose 80% of the names and insert them into the training set, the remainder into the validation set. Note that the training and validation sets are also in the same format as `category_lines`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "category_lines_train = {}\n",
        "category_lines_eval = {}\n",
        "for key in category_lines.keys():\n",
        "    category_lines_train[key] = []\n",
        "    category_lines_eval[key] = []\n",
        "for key in category_lines.keys():\n",
        "    for val in category_lines[key]:\n",
        "        if random.uniform(0, 1) < 0.8:\n",
        "            category_lines_train[key].append(val)\n",
        "        else:\n",
        "            category_lines_eval[key].append(val)\n",
        "            \n",
        "dataset_size = sum(len(category_lines_train[key]) for key in category_lines_train.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After splitting the dataset into a training and a validation set, we now have to convert the data into a numeric form suitable for training the LSTM model. For each name, we set a maximum sequence length of 15, and if a name is longer than the threshold, we truncate it (this rarely happens this dataset !). If a name is smaller than the threshold, we add a dummy `#` character to pad it to the desired length. We also batch the names in the dataset and set a batch size of 256 for all the experiments in this tutorial. The function `line_to_tensor()` returns a tensor of shape [15, 256] where each element is the index (in `all_letters`) of the corresponding character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_seq_length = 15\n",
        "max_seq_length = 15\n",
        "\n",
        "def line_to_tensor(batch_size, max_seq_length, lines, all_letters, n_letters):\n",
        "    r\"\"\"\n",
        "    Turns a list of batch_size lines into a <line_length x batch_size> tensor\n",
        "    where each element of tensor is index of corresponding letter in all_letters\n",
        "    \"\"\"\n",
        "    tensor = torch.zeros(max_seq_length, batch_size).type(torch.LongTensor)\n",
        "    for batch_idx, line in enumerate(lines):\n",
        "        # Pad/truncate line to fit to max_seq_length\n",
        "        padded_line = line[0:max_seq_length] + \"#\" * (max_seq_length - len(line))\n",
        "        for li, letter in enumerate(padded_line):\n",
        "            letter_index = all_letters.find(letter)\n",
        "            tensor[li][batch_idx] = letter_index\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before going to the model definition and attaching the privacy engine to the optimizer, we also define a few other functions for helping us fetch the batches. During training, we just draw random batches from the dataset, just like how it was done in the tutorial https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html. During evaluation, though we will be running the model in a forward pass over the entire validation set, so we can report the accuracies. The function `get_random_batch()` draws a random batch from the training/validation split (returning the names, labels and their tensor representations). In contrast, `get_all_batches()` returns all the batches.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_batch(\n",
        "    category_lines, batch_size, all_categories, all_letters, n_letters\n",
        "):\n",
        "    categories = random.choices(\n",
        "        all_categories, k=batch_size\n",
        "    )  # Selects batch_size random languages\n",
        "    lines = [random.choice(category_lines[category]) for category in categories]\n",
        "    category_tensors = torch.LongTensor(\n",
        "        [all_categories.index(category) for category in categories]\n",
        "    )\n",
        "    line_tensors = line_to_tensor(\n",
        "        batch_size, max_seq_length, lines, all_letters, n_letters\n",
        "    )\n",
        "    return categories, lines, category_tensors.to(device), line_tensors.to(device)\n",
        "\n",
        "\n",
        "def get_all_batches(\n",
        "    category_lines,\n",
        "    all_categories,\n",
        "    all_letters,\n",
        "    n_letters,\n",
        "    batch_size,\n",
        "    max_seq_length\n",
        "):\n",
        "    all_lines = [(k, x) for k, l in category_lines.items() for x in l]\n",
        "    num_samples = len(all_lines)\n",
        "    batched_samples = [\n",
        "        all_lines[i : i + batch_size] for i in range(0, num_samples, batch_size)\n",
        "    ]\n",
        "    for batch in batched_samples:\n",
        "        categories, lines = map(list, zip(*batch))\n",
        "        line_tensors = line_to_tensor(\n",
        "            batch_size, max_seq_length, lines, all_letters, n_letters\n",
        "        )\n",
        "        category_tensors = torch.LongTensor(\n",
        "            [all_categories.index(category) for category in categories]\n",
        "        )\n",
        "        yield categories, lines, category_tensors.to(device), line_tensors.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training/Evaluation Cycle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training and the evaluation functions `train()` and `evaluate()` are defined below. `train()` trains the model on a single batch and `evaluate()` runs the model on a single batch in a forward pass. During the training loop, the per-example gradients are computed and the parameters are updated subsequent to gradient clipping (to bound their sensitivity) and addition of noise.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(rnn, criterion, optimizer, category_tensors, line_tensors):\n",
        "    rnn.zero_grad()\n",
        "    hidden = rnn.init_hidden()\n",
        "    if isinstance(hidden, tuple):\n",
        "        hidden = (hidden[0].to(device), hidden[1].to(device))\n",
        "    else:\n",
        "        hidden = hidden.to(device)\n",
        "    output = rnn(line_tensors, hidden)\n",
        "    loss = criterion(output, category_tensors)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.data.item()\n",
        "\n",
        "\n",
        "def evaluate(line_tensors, rnn):\n",
        "    rnn.zero_grad()\n",
        "    hidden = rnn.init_hidden()\n",
        "    if isinstance(hidden, tuple):\n",
        "        hidden = (hidden[0].to(device), hidden[1].to(device))\n",
        "    else:\n",
        "        hidden = hidden.to(device)\n",
        "    output = rnn(line_tensors, hidden)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also define `get_eval_metrics()` for metric computation, and a helper function `category_from_output()` which extracts the highest scoring language category at the ouput of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_eval_metrics(\n",
        "    rnn,\n",
        "    category_lines,\n",
        "    all_categories,\n",
        "    all_letters,\n",
        "    n_letters,\n",
        "    batch_size,\n",
        "    max_seq_length,\n",
        "):\n",
        "    pred = []\n",
        "    truth = []\n",
        "    for categories, _, _, line_tensors in get_all_batches(\n",
        "        category_lines,\n",
        "        all_categories,\n",
        "        all_letters,\n",
        "        n_letters,\n",
        "        batch_size,\n",
        "        max_seq_length,\n",
        "    ):\n",
        "        eval_output = evaluate(line_tensors, rnn)\n",
        "        guess, _ = category_from_output(eval_output, all_categories)\n",
        "        pred.extend(guess)\n",
        "        truth.extend(categories)\n",
        "    pred = pred[: min(len(pred), len(truth))]\n",
        "    truth = truth[: min(len(pred), len(truth))]\n",
        "    return balanced_accuracy_score(truth, pred)\n",
        "\n",
        "def category_from_output(output, all_categories):\n",
        "    top_n, top_i = output.data.topk(1)  # Tensor out of Variable with .data\n",
        "    category_i = top_i.flatten()\n",
        "    return [all_categories[category] for category in category_i], category_i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two sets of hyper-parameters associated with this model. The first are hyper-parameters which we would expect in any machine learning training, such as the learning rate and batch size. The second set are related to the privacy engine, where for example we define the amount of noise added to the gradients (`noise_multiplier`), and the maximum L2 norm to which the per-sample gradients are clipped (`max_grad_norm`). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training hyper-parameters\n",
        "learning_rate = 2.0\n",
        "\n",
        "# Privacy engine hyper-parameters\n",
        "noise_multiplier = 1.0\n",
        "max_grad_norm = 1.5\n",
        "delta = 8e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the name classification model in the cell below. Note that it is a simple char-LSTM classifier, where the input characters are passed through an `nn.Embedding` layer, and are subsequently input to the DPLSTM. Also note that the batch dimension is second in all tensors, and so we run the DPLSTM in the `batch_first=False` setting. We make sure that all intermediate activations in the network also maintain this batch ordering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from opacus.layers import DPLSTM\n",
        "\n",
        "class CharNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_letters, batch_size):\n",
        "        super(CharNNClassifier, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding = nn.Embedding(n_letters, input_size)\n",
        "        self.lstm = DPLSTM(input_size, hidden_size, batch_first=False)\n",
        "        self.out_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input_emb = self.embedding(input)\n",
        "        lstm_out, _ = self.lstm(input_emb, hidden)\n",
        "        output = self.out_layer(lstm_out[-1].unsqueeze(0))\n",
        "        return output[-1]\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (\n",
        "            torch.zeros(1, self.batch_size, self.hidden_size),\n",
        "            torch.zeros(1, self.batch_size, self.hidden_size),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now proceed to instantiate the objects (privacy engine, model and optimizer) for our differentially-private LSTM training.  However, the `nn.LSTM` is replaced with a `DPLSTM` module which enables us to calculate per-example gradients. The DPLSTM however, is limited to the following functionality (this example has uses supported values of the parameters):\n",
        "1. A bias term must be present (`bias` flag set to True)\n",
        "2. Single directional (`bidirectional` set to False)\n",
        "3. Single layer (`num_layers` set to 1)\n",
        "4. No dropout supported yet\n",
        "5. Initial LSTM states (`h` and `c`) set to zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the device to run on a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define classifier parameters\n",
        "n_hidden = 128  # Number of neurons in hidden layer after LSTM\n",
        "\n",
        "rnn = CharNNClassifier(\n",
        "    n_letters, n_hidden, n_categories, n_letters, batch_size\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the privacy engine, optimizer and loss criterion for the problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opacus import PrivacyEngine\n",
        "\n",
        "privacy_engine = PrivacyEngine(\n",
        "    rnn,\n",
        "    batch_size=batch_size,\n",
        "    sample_size=dataset_size,\n",
        "    alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
        "    noise_multiplier=noise_multiplier,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    batch_first=False,\n",
        ")\n",
        "privacy_engine.attach(optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the name classifier with privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we can start training ! We will be training for 1000 iterations (where each iteration corresponds to a single batch of data). We will be reporting the privacy epsilon every `print_interval` iterations. We have also benchmarked this differentially-private model against a model without privacy and obtain almost identical performance. Further, the private model trained with Opacus incurs only minimal overhead in training time, with the differentially-private classifier only slightly slower (by a couple of minutes) than the non-private model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 100/1000 [00:20<09:33,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=100 / Loss=2.5397 / Eval Accuracy:10.82 / Ɛ = 4.10, 𝛿 = 0.00) for α = 4.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 201/1000 [00:40<04:51,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=200 / Loss=1.9222 / Eval Accuracy:30.25 / Ɛ = 5.39, 𝛿 = 0.00) for α = 4.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 301/1000 [00:57<03:33,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=300 / Loss=1.6621 / Eval Accuracy:37.86 / Ɛ = 6.44, 𝛿 = 0.00) for α = 3.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 401/1000 [01:13<03:06,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=400 / Loss=1.5630 / Eval Accuracy:41.70 / Ɛ = 7.37, 𝛿 = 0.00) for α = 3.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 501/1000 [01:30<02:14,  3.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=500 / Loss=1.6921 / Eval Accuracy:41.66 / Ɛ = 8.21, 𝛿 = 0.00) for α = 3.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 600/1000 [01:43<02:13,  3.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=600 / Loss=1.3992 / Eval Accuracy:46.72 / Ɛ = 8.99, 𝛿 = 0.00) for α = 3.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 701/1000 [01:59<01:14,  4.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=700 / Loss=1.4235 / Eval Accuracy:44.77 / Ɛ = 9.73, 𝛿 = 0.00) for α = 3.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 801/1000 [02:13<00:52,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=800 / Loss=1.4360 / Eval Accuracy:48.69 / Ɛ = 10.43, 𝛿 = 0.00) for α = 2.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 900/1000 [02:27<00:35,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=900 / Loss=1.1599 / Eval Accuracy:49.11 / Ɛ = 11.10, 𝛿 = 0.00) for α = 2.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [02:43<00:00,  6.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=1000 / Loss=1.3244 / Eval Accuracy:50.65 / Ɛ = 11.74, 𝛿 = 0.00) for α = 2.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "num_iterations = 1000\n",
        "print_interval = 100\n",
        "\n",
        "current_loss = 0\n",
        "\n",
        "for iteration in tqdm(range(1, num_iterations + 1)):\n",
        "    # Get a random training input and target batch\n",
        "    _, _, category_tensors, line_tensors = get_random_batch(\n",
        "        category_lines_train,\n",
        "        batch_size,\n",
        "        all_categories,\n",
        "        all_letters,\n",
        "        n_letters,\n",
        "    )\n",
        "    output, loss = train(\n",
        "        rnn, criterion, optimizer, category_tensors, line_tensors\n",
        "    )\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print iteration number, loss, name and guess\n",
        "    if iteration % print_every == 0:\n",
        "        acc = get_eval_metrics(\n",
        "            rnn,\n",
        "            category_lines_eval,\n",
        "            all_categories,\n",
        "            all_letters,\n",
        "            n_letters,\n",
        "            batch_size,\n",
        "            max_seq_length\n",
        "        )\n",
        "        epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(\n",
        "            delta\n",
        "        )\n",
        "        print(\n",
        "            f\"Iteration={iteration} / Loss={loss:.4f} / \"\n",
        "            f\"Eval Accuracy:{acc*100:.2f} / \"\n",
        "            f\"Ɛ = {epsilon:.2f}, 𝛿 = {delta:.2f}) for α = {best_alpha:.2f}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The differentially-private name classification model obtains an accuracy of 50.65 with an epsilon of 11.74. This shows that we can achieve a good accuracy on this task, with minimal loss of privacy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the name classifier without privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " We also run a comparison with a non-private model to see if the performance obtained with privacy is comparable to it. To do this, we keep the parameters such as learning rate and batch size the same, and only define a different instance of the model along with a separate optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnn_nodp = CharNNClassifier(\n",
        "    n_letters, n_hidden, n_categories, n_letters, batch_size\n",
        ").to(device)\n",
        "\n",
        "optimizer_nodp = torch.optim.SGD(rnn_nodp.parameters(), lr=2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 101/1000 [00:10<02:33,  5.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=100 / Loss=1.9366 / Eval Accuracy:34.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 201/1000 [00:22<04:13,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=200 / Loss=1.3896 / Eval Accuracy:48.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 301/1000 [00:34<01:51,  6.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=300 / Loss=1.1055 / Eval Accuracy:51.17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 401/1000 [00:44<01:34,  6.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=400 / Loss=0.7989 / Eval Accuracy:53.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 501/1000 [00:55<01:31,  5.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=500 / Loss=0.5729 / Eval Accuracy:55.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 601/1000 [01:05<01:15,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=600 / Loss=0.5446 / Eval Accuracy:54.81\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 702/1000 [01:15<00:47,  6.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=700 / Loss=0.3958 / Eval Accuracy:55.22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 802/1000 [01:25<00:31,  6.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=800 / Loss=0.2735 / Eval Accuracy:54.72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 901/1000 [01:36<00:18,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=900 / Loss=0.2580 / Eval Accuracy:54.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:46<00:00,  9.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration=1000 / Loss=0.2827 / Eval Accuracy:52.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "current_loss = 0\n",
        "\n",
        "for iteration in tqdm(range(1, num_iterations + 1)):\n",
        "    # Get a random training input and target batch\n",
        "    _, _, category_tensors, line_tensors = get_random_batch(\n",
        "        category_lines_train,\n",
        "        batch_size,\n",
        "        all_categories,\n",
        "        all_letters,\n",
        "        n_letters,\n",
        "    )\n",
        "    output, loss = train(\n",
        "        rnn_nodp, criterion, optimizer_nodp, category_tensors, line_tensors\n",
        "    )\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print iteration number, loss, name and guess\n",
        "    if iteration % print_every == 0:\n",
        "        acc = get_eval_metrics(\n",
        "            rnn_nodp,\n",
        "            category_lines_eval,\n",
        "            all_categories,\n",
        "            all_letters,\n",
        "            n_letters,\n",
        "            batch_size,\n",
        "            max_seq_length\n",
        "        )\n",
        "        epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(\n",
        "            delta\n",
        "        )\n",
        "        print(\n",
        "            f\"Iteration={iteration} / Loss={loss:.4f} / \"\n",
        "            f\"Eval Accuracy:{acc*100:.2f}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run the training loop again, this time without privacy and for the same number of iterations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The non-private classifier obtains an accuracy of 52.29 with the same parameters and number of epochs. While we are effectively trading off performance on the name classification task for a lower loss of privacy, the difference in accuracy is only around 1.64% at a very low epsilon of 11.74. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
